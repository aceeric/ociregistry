# Pull-only, pull-through, caching OCI Distribution Server

This chart installs a **pull-only**, **pull-through**, **caching** OCI Distribution server. That means:

1. It exclusively provides _pull_ capability. You can't push images to it, it doesn't support the `/v2/_catalog` endpoint, etc. Though you can pre-load it.
2. It provides *caching pull-through* capability to any upstream registry: internal, air-gapped, or public; supporting the following types of access: anonymous, basic auth, HTTP, HTTPS, one-way TLS, and mTLS.

This OCI distribution server is intended to satisfy one use case: the need for a Kubernetes caching pull-through registry that enables a k8s cluster to run reliably in disrupted, disconnected, intermittent and low-bandwidth (DDIL) edge environments. (However, it also nicely mitigates rate-limiting issues when doing local Kubernetes development.)

## Quick Start (three steps)

## 1) Install the chart

```shell
CHARTVER=n.n.n
helm upgrade --install ociregistry oci://quay.io/appzygy/helm-charts/ociregistry\
  --version $CHARTVER\
  --namespace ociregistry\
  --create-namespace\
  --dry-run=server
```

> Remove the `--dry-run=server` arg to actually perform the install.

By default the chart will create a `NodePort` service on port `31080` in your cluster for `containerd` to mirror to. (This is configurable via a values override.)

## 2) Configure `containerd`

Configure containerd in your Kubernetes cluster to mirror **all** image pulls to the pull-through registry. (This has been tested with containerd >= `v1.7.6`):

First, add a `config_path` entry to `/etc/containerd/config.toml` to tell containerd to load all registry mirror configurations from that directory:

```shell
   ...
   [plugins."io.containerd.grpc.v1.cri".registry]
      config_path = "/etc/containerd/certs.d"
   ...
```

Then create a configuration file that tells containerd to pull from the caching pull-through registry server in the cluster. This is an example for `_default` which indicates to containerd that **all** images should be mirrored:

```shell
mkdir -p /etc/containerd/certs.d/_default && \
cat <<EOF >| /etc/containerd/certs.d/_default/hosts.toml
[host."http://localhost:31080"]
  capabilities = ["pull", "resolve"]
  skip_verify = true
EOF
```

**Key Points:**

1. The _resolve_ capability tells containerd that a HEAD request to the server with a manifest will return a manifest digest. The _pull_ capability indicates to containerd that the image can be pulled.
2. Assuming you installed the caching pull-through OCI registry with the default `NodePort` service option on port `31080`, every host on the cluster will route `31080` to the Pod running the registry.

The `containerd` daemon _should_ detect the change and re-configure itself. If you believe that's not occurring, then `systemctl restart containerd`.

## 3) Verify

### Tail the logs on the pull-through registry pod:

```shell
kubectl -n ociregistry logs -f -l app.kubernetes.io/name=ociregistry
```

### Observe the startup logs

```shell
time="2025-04-24T21:11:41Z" level=info msg="loaded 0 manifest(s) from the file system in 102.136µs"
----------------------------------------------------------------------
OCI Registry: pull-only, pull-through, caching OCI Distribution Server
Version: vZ.Z.Z, build date: 2025-04-23T00:35:28.79Z
Started: 2025-04-24 21:11:41.727569108 +0000 UTC (port 8080)
Running as (uid:gid) 65532:65532
Process id: 1
Tls: none
Command line: /ociregistry/server --config-file /var/ociregistry/config/registry-config.yaml serve
----------------------------------------------------------------------
time="2025-04-24T21:11:41Z" level=info msg="server is running"
```

### Run `hello-world` container

```shell
kubectl run hello-world --image docker.io/hello-world:latest &&\
  sleep 5s &&\
  kubectl logs hello-world
```

### Result

```shell
Hello from Docker!
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
    (amd64)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
```
(remainder redacted for brevity...)

### Observe the **new** ociregistry log entries

```shell
time="2025-04-24T21:13:54Z" level=info msg="pulling manifest from upstream: \"docker.io/library/hello-world:latest\""
time="2025-04-24T21:13:54Z" level=info msg="echo server HEAD:/v2/library/hello-world/manifests/latest?ns=docker.io status=200 latency=501.131286ms host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:13:54Z" level=info msg="serving manifest from cache: \"docker.io/library/hello-world@sha256:c41088499908a59aae84b0a49c70e86f4731e588a737f1637e73c8c09d995654\""
time="2025-04-24T21:13:54Z" level=info msg="echo server GET:/v2/library/hello-world/manifests/sha256:c410884999?ns=docker.io status=200 latency=2.267101ms host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:13:54Z" level=info msg="pulling manifest from upstream: \"docker.io/library/hello-world@sha256:03b62250a3cb1abd125271d393fc08bf0cc713391eda6b57c02d1ef85efcc25c\""
time="2025-04-24T21:13:55Z" level=info msg="echo server GET:/v2/library/hello-world/manifests/sha256:03b62250a3?ns=docker.io status=200 latency=612.467708ms host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:13:55Z" level=info msg="echo server GET:/v2/library/hello-world/blobs/sha256:74cc54e27d?ns=docker.io status=200 latency=234.948µs host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:13:55Z" level=info msg="echo server GET:/v2/library/hello-world/blobs/sha256:e6590344b1?ns=docker.io status=200 latency=232.113µs host=localhost:31080 ip=10.200.0.232"
```

### Run `hello-world` Pod again with a different name

This time, also specify a pull policy to force `containerd` to pull the image:

```shell
kubectl run hello-world-2 --image docker.io/hello-world:latest --image-pull-policy=Always
```

### Observe new ociregistry log entries

These entries indicate that the _ociregistry_ server is serving from the image cache instead of re-pulling from Docker Hub:

```shell
time="2025-04-24T21:34:35Z" level=info msg="serving manifest from cache: \"docker.io/library/hello-world:latest\""
time="2025-04-24T21:34:35Z" level=info msg="echo server HEAD:/v2/library/hello-world/manifests/latest?ns=docker.io status=200 latency=204.413µs host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:34:36Z" level=info msg="serving manifest from cache: \"docker.io/library/hello-world:latest\""
time="2025-04-24T21:34:36Z" level=info msg="echo server HEAD:/v2/library/hello-world/manifests/latest?ns=docker.io status=200 latency=358.099µs host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:34:51Z" level=info msg="serving manifest from cache: \"docker.io/library/hello-world:latest\""
time="2025-04-24T21:34:51Z" level=info msg="echo server HEAD:/v2/library/hello-world/manifests/latest?ns=docker.io status=200 latency=313.859µs host=localhost:31080 ip=10.200.0.232"
time="2025-04-24T21:35:09Z" level=info msg="serving manifest from cache: \"docker.io/library/hello-world:latest\""
time="2025-04-24T21:35:09Z" level=info msg="echo server HEAD:/v2/library/hello-world/manifests/latest?ns=docker.io status=200 latency=836.294µs host=localhost:31080 ip=10.200.0.232"
```

## TLS

By default the server serves over HTTP in the cluster. To serve over HTTPS, the chart has the `serverTls` hash. To enable TLS:

1. Have server cert and key PEM files, and optionally a CA PEM file, on the file system.
2. Configure values like this:
   ```
   serverTls:
     enabled: true
     clientAuth: none # or 'verify'
   ```
3. Deploy the chart:
   ```
   helm upgrade --install ociregistry oci://...\
    --namespace ociregistry\
    --create-namespace\
    --values <file with contents above>.yaml\
    --set-file serverTls.cert=/tmp/localhost.crt\
    --set-file serverTls.key=/tmp/localhost.key\
    --set-file serverTls.ca=/tmp/localhost.crt
   ```

If you already have a secret in the cluster with cert, key, and (optionally) ca then configure the `serverTls` as shown below. Then omit supplying values/files for the `tls.crt`, `tls.key`, and `ca.crt` sub-keys of the `serverTls` hash. For example, suppose:

```
kubectl -n ociregistry create secret generic my-tls-secret\
  --from-file=tls.crt=/tmp/localhost.crt\
  --from-file=tls.key=/tmp/localhost.key\
  --from-file=ca.crt=/tmp/localhost.crt
```

Then you would install the ociregistry with this a values override containing this:

```
serverTls:
  secretName: my-tls-secret
  enabled: true
  clientAuth: verify # or 'none'
```

And you helm install command would look like this (omit the `--set-file` args):

```
helm upgrade --install ociregistry oci://...\
  --namespace ociregistry\
  --create-namespace\
  --values <file with contents above>.yaml
```

## Monitoring and metrics

Metrics can be enabled as follows. First enable observability. This creates the Prometheus and Grafana resources (including dashboard `ConfigMaps` for Grafana. Since these resources are created in the `ociregistry` namespace, you will need to configure Prometheus to find Service Monitors and Prometheus Rules in that namespace, or all namespaces:
```
observability:
  enabled: true
```

Then enable metrics exposition by defining a metrics port for the server to expose metrics on. There are two ways:

Using the `metrics` value:
```
metrics:
  port: <port num>
```

Or, using the `serverConfig` value:
```
serverConfig:
  configuration:
    metrics: <port num>
```

## More information

More information, including how to configure access to upstream registries for authentication and TLS, as well as additional registry features and capabilities can be found at: https://github.com/aceeric/ociregistry.

## Chart Details

{{ template "chart.versionBadge" . }}{{ template "chart.typeBadge" . }}{{ template "chart.appVersionBadge" . }}

## Chart Values

{{ template "chart.valuesSection" . }}

{{ template "helm-docs.versionFooter" . }}